{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494e08f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03991f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Osti\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import splitfolders\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a995a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "778bc62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './output/train',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd96f782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    './output/val',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\"\n",
    ")\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'output/test',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5d447da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "class_names_arr = train_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac7a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98039c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import clone_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import keras\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4121f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "import keras\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a099d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(Conv2D(hp.Int('input_units',\n",
    "                            min_value=32,\n",
    "                            max_value=256,\n",
    "                            step=32), (3, 3), input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))  \n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    for i in range(hp.Int('n_layers', 1, 4)):\n",
    "        model.add(Conv2D(hp.Int(f'conv_{i}_units',\n",
    "                                min_value=32,\n",
    "                                max_value=256,\n",
    "                                step=32), (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    for i in range(hp.Int('n_connections', 1, 4)):\n",
    "        model.add(Dense(hp.Choice(f'n_nodes',\n",
    "                                  values=[128, 256, 512, 1024])))\n",
    "        model.add(Activation('relu'))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(10))  \n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",  \n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5704104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,\n",
    " executions_per_trial=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d21c32a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [02h 25m 28s]\n",
      "val_loss: 1.0046669244766235\n",
      "\n",
      "Best val_loss So Far: 0.6349225838979086\n",
      "Total elapsed time: 03h 11m 55s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    x=train_generator,  # Pass the generator for training data\n",
    "    validation_data=validation_generator,\n",
    "    epochs=3,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(validation_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260162b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bf8ac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 64)      1792      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 254, 254, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      18464     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 125, 125, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 123008)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               15745152  \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15766698 (60.15 MB)\n",
      "Trainable params: 15766698 (60.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "None\n",
      "{'units': 16, 'input_units': 64, 'n_layers': 1, 'conv_0_units': 32, 'n_connections': 1, 'n_nodes': 128}\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_best_models()[0].summary())\n",
    "print(tuner.get_best_hyperparameters()[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cd0ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(), \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "154c2e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 154s 611ms/step - loss: 2.2891 - accuracy: 0.1013 - val_loss: 2.2887 - val_accuracy: 0.1069\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=250,\n",
    "    batch_size=32,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=31,\n",
    "    verbose=1,\n",
    "    epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e6abe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e7bcb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 117ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = tf.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5cf2449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.00      0.00      0.00       100\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.20      0.02      0.04       100\n",
      "           5       0.00      0.00      0.00       100\n",
      "           6       0.00      0.00      0.00       100\n",
      "           7       0.10      1.00      0.18       100\n",
      "           8       0.00      0.00      0.00       100\n",
      "           9       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.10      1000\n",
      "   macro avg       0.03      0.10      0.02      1000\n",
      "weighted avg       0.03      0.10      0.02      1000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   0   0   2   0   0  98   0   0]\n",
      " [  0   0   0   0   0   0   0 100   0   0]\n",
      " [  0   0   0   0   0   0   0 100   0   0]\n",
      " [  0   0   0   0   0   0   0 100   0   0]\n",
      " [  0   0   0   0   2   0   0  98   0   0]\n",
      " [  0   0   0   0   4   0   0  96   0   0]\n",
      " [  0   0   0   0   0   0   0 100   0   0]\n",
      " [  0   0   0   0   0   0   0 100   0   0]\n",
      " [  0   0   0   0   1   0   0  99   0   0]\n",
      " [  0   0   0   0   1   0   0  99   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osti\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Osti\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Osti\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(true_classes, predicted_classes))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(true_classes, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a25730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459a526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
